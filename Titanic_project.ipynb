{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e555ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train = pd.read_csv(r'C:\\Users\\Lenovo\\OneDrive\\Pulpit\\MyProjects\\titanic\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\Lenovo\\OneDrive\\Pulpit\\MyProjects\\titanic\\test.csv')\n",
    "gender_sub = pd.read_csv(r'C:\\Users\\Lenovo\\OneDrive\\Pulpit\\MyProjects\\titanic\\gender_submission.csv')\n",
    "#train_y = train['Survived']\n",
    "#test_y = test['Survived']\n",
    "\n",
    "train_y = train['Survived']\n",
    "test_y=gender_sub['Survived']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9266da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0147c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[train,test]\n",
    "for dataset in data:\n",
    "    dataset['Sex']=dataset['Sex'].map({'male':0, 'female':1})\n",
    "    dataset['Prefix'] = dataset['Name'].str.split(expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2dc9db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('PassengerId', axis=1)\n",
    "test = test.drop('PassengerId', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b700d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3b13447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.        502\n",
       "Miss.      179\n",
       "Mrs.       121\n",
       "Master.     40\n",
       "Name: Prefix, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = train['Prefix'].value_counts()\n",
    "prefix\n",
    "top_prefixes = prefix[prefix>len(train)/25]\n",
    "top_prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47bec15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Prefix'] = train['Prefix'].apply(lambda x: x if x in top_prefixes else 'Other')\n",
    "test['Prefix'] = test['Prefix'].apply(lambda x: x if x in top_prefixes else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b031cd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "Prefix        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2fc9319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age          86\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          1\n",
       "Cabin       327\n",
       "Embarked      0\n",
       "Prefix        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3353cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the columns that have more than 70% of data missing\n",
    "cols_null = train.columns[train.isnull().sum()>len(train)*0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b5f6f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(cols_null, axis=1)\n",
    "test = test.drop(cols_null, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe4f8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are substituting one missing value with the mean value for Fare\n",
    "test['Fare'] = test['Fare'].fillna(test['Fare'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d20f848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      32.204208\n",
       "std       49.693429\n",
       "min        0.000000\n",
       "25%        7.910400\n",
       "50%       14.454200\n",
       "75%       31.000000\n",
       "max      512.329200\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Fare.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2a5ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating more generalized categories for fare\n",
    "train['Fare_cat'] = pd.qcut(train.Fare, q=4, labels=[1,2,3,4]) #categories based on price of ticket\n",
    "test['Fare_cat'] = pd.qcut(test.Fare, q=4, labels=[1,2,3,4])\n",
    "train['Fare_cat'] = train['Fare_cat'].astype('int64')\n",
    "test['Fare_cat'] = test['Fare_cat'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2ef7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we have fare categories, we can drop 'Fare' column\n",
    "train=train.drop('Fare', axis=1)\n",
    "test = test.drop('Fare', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07eb1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making combined category for family on board\n",
    "data=[train,test]\n",
    "for dataset in data:\n",
    "    dataset['Fam'] = dataset['SibSp']+dataset['Parch']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "112c82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['SibSp', 'Parch'], axis=1)\n",
    "test = test.drop(['SibSp', 'Parch'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4f08959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "Ticket        0\n",
       "Embarked      2\n",
       "Prefix        0\n",
       "Fare_cat      0\n",
       "Fam           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b391576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        int64\n",
       "Name         object\n",
       "Sex           int64\n",
       "Age         float64\n",
       "Ticket       object\n",
       "Embarked     object\n",
       "Prefix       object\n",
       "Fare_cat      int64\n",
       "Fam           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5d9c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we got prefix we can get rid of 'Name' category\n",
    "#we can also drop information about the ticket since we decided to drop 'Cabin' column due to amount of lost data\n",
    "#the rest of object categories can be transformed by one hot encoding because they don't have too much unique values\n",
    "\n",
    "train = train.drop(['Ticket', 'Name'], axis=1)\n",
    "test = test.drop(['Ticket', 'Name'], axis=1)\n",
    "obj_cats = train.columns[train.dtypes=='object']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34ec878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Embarked', 'Prefix'], dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fdadb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cats = train.columns[train.dtypes!='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3aceef4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'Fare_cat', 'Fam'], dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93529e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer())]),\n",
       "                                      Pclass  Sex   Age  Fare_cat  Fam\n",
       "0         3    0  22.0         1    1\n",
       "1         1    1  38.0         4    1\n",
       "2         3    1  26.0         2    0\n",
       "3         1    1  35.0         4    1\n",
       "4         3    0  35.0         2    0\n",
       "..      ...  ...   ...       ...  ...\n",
       "886       2    0  27.0         2    0\n",
       "887       1    1  19.0         3    0\n",
       "888       3    1   NaN         3    3\n",
       "889       1    0  26.0         3    0\n",
       "890       3    0  32.0         1    0\n",
       "\n",
       "[891 rows x 5 columns]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;one_hot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                     Embarked Prefix\n",
       "0          S    Mr.\n",
       "1          C   Mrs.\n",
       "2          S  Miss.\n",
       "3          S   Mrs.\n",
       "4          S    Mr.\n",
       "..       ...    ...\n",
       "886        S  Other\n",
       "887        S  Miss.\n",
       "888        S  Miss.\n",
       "889        C    Mr.\n",
       "890        Q    Mr.\n",
       "\n",
       "[891 rows x 2 columns])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer())]),\n",
       "                                      Pclass  Sex   Age  Fare_cat  Fam\n",
       "0         3    0  22.0         1    1\n",
       "1         1    1  38.0         4    1\n",
       "2         3    1  26.0         2    0\n",
       "3         1    1  35.0         4    1\n",
       "4         3    0  35.0         2    0\n",
       "..      ...  ...   ...       ...  ...\n",
       "886       2    0  27.0         2    0\n",
       "887       1    1  19.0         3    0\n",
       "888       3    1   NaN         3    3\n",
       "889       1    0  26.0         3    0\n",
       "890       3    0  32.0         1    0\n",
       "\n",
       "[891 rows x 5 columns]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;one_hot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                     Embarked Prefix\n",
       "0          S    Mr.\n",
       "1          C   Mrs.\n",
       "2          S  Miss.\n",
       "3          S   Mrs.\n",
       "4          S    Mr.\n",
       "..       ...    ...\n",
       "886        S  Other\n",
       "887        S  Miss.\n",
       "888        S  Miss.\n",
       "889        C    Mr.\n",
       "890        Q    Mr.\n",
       "\n",
       "[891 rows x 2 columns])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>     Pclass  Sex   Age  Fare_cat  Fam\n",
       "0         3    0  22.0         1    1\n",
       "1         1    1  38.0         4    1\n",
       "2         3    1  26.0         2    0\n",
       "3         1    1  35.0         4    1\n",
       "4         3    0  35.0         2    0\n",
       "..      ...  ...   ...       ...  ...\n",
       "886       2    0  27.0         2    0\n",
       "887       1    1  19.0         3    0\n",
       "888       3    1   NaN         3    3\n",
       "889       1    0  26.0         3    0\n",
       "890       3    0  32.0         1    0\n",
       "\n",
       "[891 rows x 5 columns]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>    Embarked Prefix\n",
       "0          S    Mr.\n",
       "1          C   Mrs.\n",
       "2          S  Miss.\n",
       "3          S   Mrs.\n",
       "4          S    Mr.\n",
       "..       ...    ...\n",
       "886        S  Other\n",
       "887        S  Miss.\n",
       "888        S  Miss.\n",
       "889        C    Mr.\n",
       "890        Q    Mr.\n",
       "\n",
       "[891 rows x 2 columns]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('imputer', SimpleImputer())]),\n",
       "                                      Pclass  Sex   Age  Fare_cat  Fam\n",
       "0         3    0  22.0         1    1\n",
       "1         1    1  38.0         4    1\n",
       "2         3    1  26.0         2    0\n",
       "3         1    1  35.0         4    1\n",
       "4         3    0  35.0         2    0\n",
       "..      ...  ...   ...       ...  ...\n",
       "886       2    0  27.0         2    0\n",
       "887       1    1  19.0         3    0\n",
       "888       3    1   NaN         3    3\n",
       "889       1    0  26.0         3    0\n",
       "890       3    0  32.0         1    0\n",
       "\n",
       "[891 rows x 5 columns]),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('one_hot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                     Embarked Prefix\n",
       "0          S    Mr.\n",
       "1          C   Mrs.\n",
       "2          S  Miss.\n",
       "3          S   Mrs.\n",
       "4          S    Mr.\n",
       "..       ...    ...\n",
       "886        S  Other\n",
       "887        S  Miss.\n",
       "888        S  Miss.\n",
       "889        C    Mr.\n",
       "890        Q    Mr.\n",
       "\n",
       "[891 rows x 2 columns])])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_cols = train[num_cats]\n",
    "cat_cols = train[obj_cats]\n",
    "pipeline_cat = Pipeline([('one_hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "pipeline_num = Pipeline([('imputer', SimpleImputer(strategy='mean'))])\n",
    "cat_transformed = pipeline_cat.fit_transform(cat_cols)\n",
    "\n",
    "#cat_transformed = pd.DataFrame(cat_transformed, columns = cat_cols.columns, index= cat_cols.index)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [('num', pipeline_num, num_cols), ('cat', pipeline_cat, cat_cols)])\n",
    "preprocessor\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6dc89e64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No valid specification of the columns. Only a scalar, list or slice of all integers or all strings, or boolean mask is allowed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [58], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      6\u001b[0m pipeline_model \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, model)])\n\u001b[1;32m----> 7\u001b[0m \u001b[43mpipeline_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\lenovo\\desktop\\machine learning\\projekt_mieszkania\\venv\\lib\\site-packages\\sklearn\\pipeline.py:378\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    377\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 378\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\users\\lenovo\\desktop\\machine learning\\projekt_mieszkania\\venv\\lib\\site-packages\\sklearn\\pipeline.py:336\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    334\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    337\u001b[0m     cloned_transformer,\n\u001b[0;32m    338\u001b[0m     X,\n\u001b[0;32m    339\u001b[0m     y,\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    341\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    342\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    344\u001b[0m )\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\users\\lenovo\\desktop\\machine learning\\projekt_mieszkania\\venv\\lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\lenovo\\desktop\\machine learning\\projekt_mieszkania\\venv\\lib\\site-packages\\sklearn\\pipeline.py:870\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 870\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\users\\lenovo\\desktop\\machine learning\\projekt_mieszkania\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:687\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[1;32m--> 687\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m    690\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[1;32mc:\\users\\lenovo\\desktop\\machine learning\\projekt_mieszkania\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:374\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[0;32m    373\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[1;32m--> 374\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[1;32mc:\\users\\lenovo\\desktop\\machine learning\\projekt_mieszkania\\venv\\lib\\site-packages\\sklearn\\utils\\__init__.py:374\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m\"\"\"Get feature column indices for input data X and key.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03mFor accepted values of `key`, see the docstring of\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m:func:`_safe_indexing_column`.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    372\u001b[0m n_columns \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 374\u001b[0m key_dtype \u001b[38;5;241m=\u001b[39m \u001b[43m_determine_key_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m key:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# we get an empty list\u001b[39;00m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[1;32mc:\\users\\lenovo\\desktop\\machine learning\\projekt_mieszkania\\venv\\lib\\site-packages\\sklearn\\utils\\__init__.py:287\u001b[0m, in \u001b[0;36m_determine_key_type\u001b[1;34m(key, accept_slice)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n",
      "\u001b[1;31mValueError\u001b[0m: No valid specification of the columns. Only a scalar, list or slice of all integers or all strings, or boolean mask is allowed"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "pipeline_model = Pipeline([('preprocessor', preprocessor), ('model', model)])\n",
    "pipeline_model.fit(train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2f127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
